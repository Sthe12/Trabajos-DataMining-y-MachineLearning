{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 10 Convolutional Neural Networks\n",
        "CNNs) are a specialized type of artificial neural network designed for processing grid-like data, such as images. They are particularly well-suited for computer vision tasks due to their ability to automatically learn hierarchical representations from raw pixel values.\n",
        "CNNs have been highly successful in various applications, such as image classification, object detection, image segmentation, and more."
      ],
      "metadata": {
        "collapsed": false,
        "id": "t_t_SQUmhQHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras import layers, models\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "id": "mGEiLbgFhQHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dataset Preparation:\n",
        "* Download and preprocess the Caltech-256 dataset. You can use the tensorflow_datasets library to load the dataset conveniently.\n",
        "* Normalize the pixel values of the images to the range [0, 1].\n",
        "* Split the dataset into training and testing sets."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ienLGTkkhQHY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": [
        "(train_dataset, test_dataset), dataset_info = tfds.load(\n",
        "    name='caltech101',\n",
        "    split=['train[:80%]', 'train[80%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        "    data_dir='C:\\\\Users\\\\ivanc\\\\PycharmProjects\\\\scientificProject',\n",
        "\n",
        ")\n",
        "\n",
        "num_classes = dataset_info.features['label'].num_classes\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_image).shuffle(10000).batch(150)\n",
        "test_dataset = test_dataset.map(preprocess_image).batch(150)"
      ],
      "metadata": {
        "id": "vFkGk4BahQHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Build the CNN Model:\n",
        "Define a CNN model with the following architecture:\n",
        "* Convolutional Layer 1: 32 filters, kernel size (3x3), ReLU activation.\n",
        "* Max Pooling Layer 1: Pooling size (2x2).\n",
        "* Convolutional Layer 2: 64 filters, kernel size (3x3), ReLU activation.\n",
        "* Max Pooling Layer 2: Pooling size (2x2).\n",
        "* Flatten the feature maps.\n",
        "* Fully Connected Layer 1: 128 units, ReLU activation.\n",
        "* Output Layer: Number of units equal to the number of classes in the Caltech-101 dataset."
      ],
      "metadata": {
        "collapsed": false,
        "id": "DJJTM1_ohQHq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "Hmo2d7BQhQHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Training the Model:\n",
        "* Compile the model with an appropriate optimizer and loss function.\n",
        "* Train the model using the training dataset and validate it using the testing dataset.\n",
        "* Observe the training process, including the loss and accuracy metrics."
      ],
      "metadata": {
        "collapsed": false,
        "id": "1DiJGImDhQH1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "17/17 [==============================] - 24s 306ms/step - loss: 7.6752 - accuracy: 0.0127 - val_loss: 4.6297 - val_accuracy: 0.0098\n",
            "Epoch 2/25\n",
            "17/17 [==============================] - 5s 204ms/step - loss: 4.5970 - accuracy: 0.0237 - val_loss: 4.5587 - val_accuracy: 0.0359\n",
            "Epoch 3/25\n",
            "17/17 [==============================] - 5s 226ms/step - loss: 4.3307 - accuracy: 0.0842 - val_loss: 4.2560 - val_accuracy: 0.1193\n",
            "Epoch 4/25\n",
            "17/17 [==============================] - 5s 204ms/step - loss: 3.5195 - accuracy: 0.2655 - val_loss: 4.0057 - val_accuracy: 0.1601\n",
            "Epoch 5/25\n",
            "17/17 [==============================] - 6s 213ms/step - loss: 2.3449 - accuracy: 0.5061 - val_loss: 4.0063 - val_accuracy: 0.2108\n",
            "Epoch 6/25\n",
            "17/17 [==============================] - 5s 218ms/step - loss: 1.3214 - accuracy: 0.7165 - val_loss: 3.9759 - val_accuracy: 0.2173\n",
            "Epoch 7/25\n",
            "17/17 [==============================] - 6s 242ms/step - loss: 0.5981 - accuracy: 0.8926 - val_loss: 4.1797 - val_accuracy: 0.2451\n",
            "Epoch 8/25\n",
            "17/17 [==============================] - 5s 212ms/step - loss: 0.2186 - accuracy: 0.9722 - val_loss: 4.5293 - val_accuracy: 0.2108\n",
            "Epoch 9/25\n",
            "17/17 [==============================] - 6s 210ms/step - loss: 0.0899 - accuracy: 0.9926 - val_loss: 4.8887 - val_accuracy: 0.2386\n",
            "Epoch 10/25\n",
            "17/17 [==============================] - 5s 210ms/step - loss: 0.0342 - accuracy: 0.9988 - val_loss: 5.1385 - val_accuracy: 0.2304\n",
            "Epoch 11/25\n",
            "17/17 [==============================] - 7s 221ms/step - loss: 0.0178 - accuracy: 0.9992 - val_loss: 5.1396 - val_accuracy: 0.2435\n",
            "Epoch 12/25\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_dataset, epochs=25, validation_data=test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMD-uxQbhQH7",
        "outputId": "a178c6b9-c2ad-446a-878c-e56ae8a6e80a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Understanding Parameter Sharing and Local Receptive Fields:\n",
        "* Analyze the number of learnable parameters in each layer of the CNN model.\n",
        "\n",
        "¿What is parameter sharing? ¿What's its role in reducing the model's complexity?"
      ],
      "metadata": {
        "collapsed": false,
        "id": "buRaoRLYhQIB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ff85f9deb473>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of trainable parameters in the model: {num_params}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "num_params = model.count_params()\n",
        "print(f\"Number of trainable parameters in the model: {num_params}\")"
      ],
      "metadata": {
        "id": "Ry2y0HPUhQIF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "ace5da55-c472-4bcb-9e50-c3ceb0f0d597"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Evaluation and Interpretation:\n",
        "* Evaluate the model's performance on the testing dataset and calculate the accuracy.\n",
        "* Visualize some misclassified images and discuss the possible reasons for misclassifications."
      ],
      "metadata": {
        "collapsed": false,
        "id": "U-H9enKqhQIL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Accuracy on the test set: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "xfZYhsvQhQIM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "misclassified_images = []\n",
        "misclassified_labels = []\n",
        "for image, label in test_dataset:\n",
        "    predictions = model.predict(image)\n",
        "    predicted_label = np.argmax(predictions, axis=1)\n",
        "    misclassified_idx = np.where(predicted_label != label.numpy())[0]\n",
        "    for idx in misclassified_idx:\n",
        "        misclassified_images.append(image[idx])\n",
        "        misclassified_labels.append(predicted_label[idx])\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(len(misclassified_images)):\n",
        "    plt.subplot(5, 5, i+1)\n",
        "    plt.imshow(misclassified_images[i])\n",
        "    plt.title(f\"Predicted: {misclassified_labels[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "s2KgsUwQhQIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Pick a sample image and show the feature maps activated by the convolutional layers"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ReNsjHS-hQIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "sample_image, _ = next(itertools.islice(iter(test_dataset), 0, 1))\n",
        "sample_image = sample_image[:1]\n",
        "\n",
        "activation_model = models.Model(inputs=model.input,\n",
        "                                outputs=[layer.output for layer in model.layers])\n",
        "# activation_model = models.Model(inputs=model.input, outputs=model.layers[4].output)\n",
        "activations = activation_model.predict(sample_image)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, activation in enumerate(activations):\n",
        "    plt.subplot(2, 4, i+1)\n",
        "    try:\n",
        "        plt.imshow(activation[0, :, :, 0], cmap='viridis')\n",
        "    except:\n",
        "        pass\n",
        "    plt.title(f\"Activation {i+1}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MelMN9SRhQIR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}